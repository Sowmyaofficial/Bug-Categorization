{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM95SMCE2yk3uo9jyV2VORe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"n5vL2tTfc7_d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666266849957,"user_tz":-330,"elapsed":2801,"user":{"displayName":"SAIKRISHNA REDDY","userId":"04954870555826076895"}},"outputId":"0309d838-d020-4de6-c2f3-24dc2c317dd4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","from nltk import sent_tokenize\n","from gensim.utils import simple_preprocess\n","nltk.download('punkt')\n","\n","from sklearn.preprocessing import StandardScaler\n","import pickle\n","from sklearn import preprocessing"]},{"cell_type":"code","source":["def onehot(ft,dataset):\n","    label = [x for x in dataset[ft].value_counts().head(10).index]\n","    for i in label:\n","        dataset[i] = np.where(dataset[ft] ==i,1,0)\n","\n","def test(file):\n","\n","    data = pd.read_csv(file,usecols = ['Summary','Issue Type','Status','Assignee','Priority','Created','Major blocks','Sub-blocks'])\n","    i = data[(data['Issue Type'] != 'Bug')].index\n","    data = data.drop(i,axis=0)\n","\n","    df = pd.DataFrame(columns = ['Summary','Majorblocks','Sub-blocks','Assignee'])\n","    df.Summary = data['Summary']\n","    df.Assignee = data['Assignee']\n","    df.Majorblocks = data['Major blocks']\n","\n","\n","    label_encoder = preprocessing.LabelEncoder()\n","    data['Status'] = label_encoder.fit_transform(data['Status'])\n","    data['Priority'] = label_encoder.fit_transform(data['Priority'])\n","    data['Major blocks'] = label_encoder.fit_transform(data['Major blocks'])\n","\n","    onehot('Assignee',data)\n","\n","    data['Date'] = pd.to_datetime(data['Created']).dt.date\n","    data['Creatd_Time'] = pd.to_datetime(data['Created']).dt.time\n","\n","    data[\"created_day\"] = pd.to_datetime(data.Date, format=\"%Y-%m-%d\").dt.day\n","    data[\"created_month\"] = pd.to_datetime(data.Date, format=\"%Y-%m-%d\").dt.month\n","\n","    # ind=data['Date'].index\n","    # ind = list(ind)\n","    # k=0\n","    # index = []\n","    # for i in data['Date'].values:\n","    #     if dt.strptime(str(i), \"%Y-%m-%d\")  >  dt.strptime(\"2022-09-27\", \"%Y-%m-%d\"):\n","    #         # if (dt.strptime(str(j), \"%H:%M:%S\") > dt.strptime(\"20:41:00\", \"%H:%M:%S\")):\n","    #         index.append(ind[k])\n","    #         k=k+1\n","    # print(index)\n","\n","    df['Date'] = data['Date']\n","    df['Time'] = data['Creatd_Time']\n","    \n","\n","    data = data.drop(['Date','Created','Issue Type','Assignee','Creatd_Time'],axis=1)\n","\n","   \n","\n","    data['Summary'] = data['Summary'].apply(lambda x : re.sub('[^a-zA-Z0-9]',' ',x))\n","    corpus1 = []\n","    index1 = list(data.index)\n","    i=0\n","    lemmatizer=WordNetLemmatizer()\n","    for j in range(0,len(data.Summary)):\n","        title = data.Summary[index1[i]]\n","        title = title.lower()\n","        title = title.split()\n","        title = [lemmatizer.lemmatize(word) for word in title if not word in stopwords.words('english')]\n","        title = ' '.join(title)\n","        corpus1.append(title)\n","        i=i+1\n","\n","    from sklearn.feature_extraction.text import TfidfVectorizer\n","    tv = TfidfVectorizer(max_features=2500)\n","    X = tv.fit_transform(corpus1).toarray()\n","    data.Summary = X\n","    \n","    \n","\n","    sc = StandardScaler()\n","    x = data\n","    x = sc.fit_transform(x)\n","\n","\n","    model1 = open(\"RFS_SUB.pkl\",'rb')\n","    #model2 = open(\"RFH.pkl\",'rb')\n","\n","    model1_RFS = pickle.load(model1)\n","\n","    pred1 = model1_RFS.predict(x)\n","\n","    index = data.index\n","    j=0\n","    for i in pred1:\n","        df['Sub-blocks'][index[j]] = i\n","        j=j+1\n","    \n","    df.to_csv('res_sub.csv')\n","    print(df.head(20))\n","\n","\n","    \n","\n","    #print(pred1)\n","    #print(pred2)"],"metadata":{"id":"iKnvxHf7u5tv","executionInfo":{"status":"ok","timestamp":1666267369753,"user_tz":-330,"elapsed":859,"user":{"displayName":"SAIKRISHNA REDDY","userId":"04954870555826076895"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["test(\"/content/sub_test.csv\")"],"metadata":{"id":"pCThs0mSmGVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666269040128,"user_tz":-330,"elapsed":907,"user":{"displayName":"SAIKRISHNA REDDY","userId":"04954870555826076895"}},"outputId":"13114a22-0eeb-49f2-919d-f64a0222422f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["                                              Summary      Majorblocks  \\\n","0   LSU FV: Store cross cache misaligned with 2nd ...  Load Store Unit   \n","1        [TGV] Correlation: Look into vfmerge latency        Interrupt   \n","2   [TGV]:: vsetvli instruction not retaining prev...  Execution Unit    \n","3   Design considering the wrong cause code for Ma...        Interrupt   \n","4   Assertion in LST pipe of LSU On L2 testing of ...  Load Store Unit   \n","5   [TGV] LSU requesting to to claim an LTB in Bal...  Load Store Unit   \n","6                       [TGV] vmv1r.v WRData Mismatch  Execution Unit    \n","7   [TGV] Assert: LSTO Store Data Issued must matc...  Load Store Unit   \n","8   [TGV] Assertion Failure : VexPipe : credit ove...  Execution Unit    \n","9                      [TGV] vsetResolveStall_ID Hang  Execution Unit    \n","10  [TGV] LSU sends wrong load data to LTB (differ...  Load Store Unit   \n","11  [TGV] Recently added assertion in MallardTileV...  Execution Unit    \n","12      [TGV] LSU: lsta_srcReg unstable during unroll  Load Store Unit   \n","13  [TGV]Assertion Failure : make sure we don't ma...  Execution Unit    \n","14        Assertion Failure: HWPF BPM retrain counter  Load Store Unit   \n","15             [TGV] Fix bugs found in vlseg4e# tests  Execution Unit    \n","16             [TGV] LSU sends wrong load data to LTB  Load Store Unit   \n","17  Assertion Failure: SiFive_FexPipe_assert: FEX ...  Execution Unit    \n","18  MSHR Entry Valid Non-Reusable Hang failure in ...  Execution Unit    \n","19    Assertion Failure: SiFive_HwpfBitPattern_assert  Execution Unit    \n","\n","        Sub-blocks           Assignee        Date      Time  \n","0       Scalar ROB       John Ingalls  2022-09-27  20:41:00  \n","1       Scalar ROB     Nicolas Brunie  2022-09-27  03:05:00  \n","2           Vector     Nicolas Brunie  2022-09-26  06:50:00  \n","3       Scalar ROB   Satish Bhavanari  2022-09-24  00:06:00  \n","4       Scalar ROB       John Ingalls  2022-09-23  14:33:00  \n","5       Scalar ROB  Yohann Rabefarihy  2022-09-23  10:05:00  \n","6           Vector     Nicolas Brunie  2022-09-22  12:22:00  \n","7       Scalar ROB  Srivatsa Yogendra  2022-09-22  11:18:00  \n","8          LSTPipe     Nicolas Brunie  2022-09-22  06:28:00  \n","9          Vexpipe      David Kravitz  2022-09-21  16:33:00  \n","10      Scalar ROB  Srivatsa Yogendra  2022-09-21  13:18:00  \n","11            PRF    Andrew Hanselman  2022-09-21  13:14:00  \n","12      Scalar ROB       John Ingalls  2022-09-20  16:39:00  \n","13  Floating point        Ishita Shah  2022-09-20  09:08:00  \n","14      Scalar ROB     Binayak Tiwari  2022-09-19  19:51:00  \n","15          Vector            Brad Wu  2022-09-19  18:07:00  \n","16      Scalar ROB      David Kravitz  2022-09-19  11:55:00  \n","17            PRF        John Ingalls  2022-09-19  11:42:00  \n","18            PRF        John Ingalls  2022-09-19  03:04:00  \n","19          Vector     Binayak Tiwari  2022-09-18  23:29:00  \n"]}]},{"cell_type":"code","source":["from datetime import datetime as dt"],"metadata":{"id":"zvL7Pphs53uv","executionInfo":{"status":"ok","timestamp":1666266851036,"user_tz":-330,"elapsed":3,"user":{"displayName":"SAIKRISHNA REDDY","userId":"04954870555826076895"}}},"execution_count":4,"outputs":[]}]}